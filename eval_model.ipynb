{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3663716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################\n",
      "#####    CONFIGURATION    #####\n",
      "###############################\n",
      "\n",
      "Steps:\n",
      "------\n",
      " (1) YamlConfig with config_file=./config.yaml, config_name=default, config_folder=/home/rpdemilt/climate_downscaling/neural-operators-weather-downscaling/src/neuraloperators/config\n",
      " (2) YamlConfig with config_file=None, config_name=None, config_folder=/home/rpdemilt/climate_downscaling/neural-operators-weather-downscaling/src/neuraloperators/config\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Configuration:\n",
      "--------------\n",
      "\n",
      "n_params_baseline=None\n",
      "verbose=True\n",
      "arch=tfno2d\n",
      "distributed.use_distributed=False\n",
      "distributed.wireup_info=mpi\n",
      "distributed.wireup_store=tcp\n",
      "distributed.model_parallel_size=2\n",
      "distributed.seed=5544\n",
      "tfno2d.data_channels=3\n",
      "tfno2d.out_channels=3\n",
      "tfno2d.n_modes_height=8\n",
      "tfno2d.n_modes_width=8\n",
      "tfno2d.hidden_channels=32\n",
      "tfno2d.lifting_channels=256\n",
      "tfno2d.projection_channels=256\n",
      "tfno2d.n_layers=4\n",
      "tfno2d.domain_padding=None\n",
      "tfno2d.domain_padding_mode=one-sided\n",
      "tfno2d.fft_norm=forward\n",
      "tfno2d.norm=group_norm\n",
      "tfno2d.skip=linear\n",
      "tfno2d.implementation=factorized\n",
      "tfno2d.separable=0\n",
      "tfno2d.preactivation=0\n",
      "tfno2d.use_mlp=1\n",
      "tfno2d.mlp.expansion=0.5\n",
      "tfno2d.mlp.dropout=0\n",
      "tfno2d.factorization=None\n",
      "tfno2d.rank=1.0\n",
      "tfno2d.fixed_rank_modes=None\n",
      "tfno2d.dropout=0.0\n",
      "tfno2d.tensor_lasso_penalty=0.0\n",
      "tfno2d.joint_factorization=False\n",
      "tfno2d.fno_block_precision=full\n",
      "tfno2d.stabilizer=None\n",
      "tfno2d.local=True\n",
      "tfno2d.checkpoint_path=checkpoints_wtk/fno_16modes_with_locallayers/\n",
      "dfno.data_channels=2\n",
      "dfno.out_channels=2\n",
      "dfno.n_modes_height=16\n",
      "dfno.n_modes_width=16\n",
      "dfno.hidden_channels=32\n",
      "dfno.lifting_channels=256\n",
      "dfno.projection_channels=256\n",
      "dfno.n_layers=4\n",
      "dfno.domain_padding=None\n",
      "dfno.domain_padding_mode=one-sided\n",
      "dfno.fft_norm=forward\n",
      "dfno.norm=group_norm\n",
      "dfno.skip=linear\n",
      "dfno.implementation=factorized\n",
      "dfno.separable=0\n",
      "dfno.preactivation=0\n",
      "dfno.use_mlp=1\n",
      "dfno.mlp.expansion=0.5\n",
      "dfno.mlp.dropout=0\n",
      "dfno.factorization=None\n",
      "dfno.rank=1.0\n",
      "dfno.fixed_rank_modes=None\n",
      "dfno.dropout=0.0\n",
      "dfno.tensor_lasso_penalty=0.0\n",
      "dfno.joint_factorization=False\n",
      "dfno.fno_block_precision=full\n",
      "dfno.stabilizer=None\n",
      "dfno.num_rrdb=12\n",
      "dfno.local=False\n",
      "dfno.checkpoint_path=checkpoints_wtk/dfno_16modes/\n",
      "duno.data_channels=2\n",
      "duno.out_channels=2\n",
      "duno.hidden_channels=64\n",
      "duno.lifting_channels=256\n",
      "duno.projection_channels=256\n",
      "duno.n_layers=5\n",
      "duno.uno_out_channels=[64, 64, 64, 64, 64]\n",
      "duno.uno_n_modes=[[5, 5], [5, 5], [5, 5], [5, 5], [5, 5]]\n",
      "duno.uno_scalings=[[1.0, 1.0], [0.5, 0.5], [1, 1], [1, 1], [2, 2]]\n",
      "duno.domain_padding=None\n",
      "duno.domain_padding_mode=one-sided\n",
      "duno.fft_norm=forward\n",
      "duno.norm=group_norm\n",
      "duno.skip=linear\n",
      "duno.implementation=factorized\n",
      "duno.separable=0\n",
      "duno.preactivation=0\n",
      "duno.use_mlp=1\n",
      "duno.mlp.expansion=0.5\n",
      "duno.mlp.dropout=0\n",
      "duno.factorization=None\n",
      "duno.rank=1.0\n",
      "duno.fixed_rank_modes=None\n",
      "duno.joint_factorization=False\n",
      "duno.dropout=0.0\n",
      "duno.tensor_lasso_penalty=0.0\n",
      "duno.fno_block_precision=full\n",
      "duno.stabilizer=None\n",
      "duno.num_rrdb=12\n",
      "duno.local=False\n",
      "duno.checkpoint_path=checkpoints_wtk/duno/\n",
      "dcno.data_channels=2\n",
      "dcno.out_channels=2\n",
      "dcno.in_size_h=160\n",
      "dcno.in_size_w=160\n",
      "dcno.N_layers=3\n",
      "dcno.num_rrdb=12\n",
      "dcno.checkpoint_path=checkpoints_wtk/dcno/\n",
      "dafno.patch_size=8\n",
      "dafno.data_channels=2\n",
      "dafno.out_channels=2\n",
      "dafno.embed_dim=768\n",
      "dafno.depth=12\n",
      "dafno.mlp_ratio=4\n",
      "dafno.drop_rate=0.0\n",
      "dafno.drop_path_rate=0.0\n",
      "dafno.num_blocks=8\n",
      "dafno.num_rrdb=12\n",
      "dafno.checkpoint_path=checkpoints_wtk/dafno/\n",
      "opt.n_epochs=400\n",
      "opt.learning_rate=0.005\n",
      "opt.training_loss=l2\n",
      "opt.weight_decay=0.0001\n",
      "opt.amp_autocast=False\n",
      "opt.scheduler_T_max=500\n",
      "opt.scheduler_patience=5\n",
      "opt.scheduler=StepLR\n",
      "opt.step_size=60\n",
      "opt.gamma=0.5\n",
      "data.positional_encoding=False\n",
      "checkpoint.save_checkpoint=True\n",
      "patching.levels=0\n",
      "patching.padding=0\n",
      "patching.stitching=False\n",
      "wandb.log=True\n",
      "wandb.group=rdemilt-spatial-informatics-group-org\n",
      "wandb.project=climate-downscaling\n",
      "wandb.entity=rdemilt\n",
      "wandb.sweep=False\n",
      "wandb.log_output=True\n",
      "wandb.log_test_interval=1\n",
      "\n",
      "###############################\n",
      "tensor([  6.3024, 278.3945,  18.4262]) <class 'torch.Tensor'>\n",
      "tensor([  6.3024, 278.3945,  18.4262]) <class 'torch.Tensor'>\n",
      "choose local blocks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TFNO2d(\n",
       "  (shiftmean_x): ShiftMean()\n",
       "  (shiftmean_y): ShiftMean()\n",
       "  (fno_blocks): LocalFNOBlocks(\n",
       "    (convs): SpectralConv(\n",
       "      (weight): ModuleList(\n",
       "        (0-3): 4 x ComplexDenseTensor(shape=torch.Size([32, 32, 8, 5]), rank=None)\n",
       "      )\n",
       "    )\n",
       "    (fno_skips): ModuleList(\n",
       "      (0-3): 4 x Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (differential): ModuleList(\n",
       "      (0-3): 4 x FiniteDifferenceConvolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False, padding_mode=circular)\n",
       "      )\n",
       "    )\n",
       "    (mlp): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (fcs): ModuleList(\n",
       "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp_skips): ModuleList(\n",
       "      (0-3): 4 x SoftGating()\n",
       "    )\n",
       "    (norm): ModuleList(\n",
       "      (0-7): 8 x GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lifting): MLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (projection): MLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import h5py\n",
    "from einops import rearrange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from configmypy import ConfigPipeline, YamlConfig\n",
    "from torch import nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from scripts.baseline.utils import *\n",
    "from src.data_loading import getTestData\n",
    "from src.neuraloperators.neuralop import get_model\n",
    "from src.neuraloperators.neuralop.training import setup\n",
    "\n",
    "months  = [\n",
    "    str(i).rjust(2,'0') for i in range(1,13,1)\n",
    "]\n",
    "\n",
    "data_name = 'era5'\n",
    "data_path = './datasets/era5_new'\n",
    "method = 'bicubic'\n",
    "crop_size = 128\n",
    "n_patches = 8\n",
    "noise_ratio = 0.0\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32\n",
    "seed = 5544\n",
    "upsampling_factor = 4\n",
    "zero_shot = True\n",
    "zero_shot_upsampling_factor = 16\n",
    "\n",
    "project_dir = '/home/rpdemilt/climate_downscaling/neural-operators-weather-downscaling'\n",
    "\n",
    "resol, n_fields, mean, std = get_data_info(data_name)\n",
    "test1_loader, test2_loader = None, None\n",
    "\n",
    "upsampling_factor = zero_shot_upsampling_factor\n",
    "\n",
    "pipe = ConfigPipeline(\n",
    "        [\n",
    "            YamlConfig(\n",
    "                \"./config.yaml\", config_name=\"default\", config_folder=os.path.join(project_dir,'src/neuraloperators/config')\n",
    "            ),\n",
    "            YamlConfig(config_folder=os.path.join(project_dir,'src/neuraloperators/config')),\n",
    "        ]\n",
    "    )\n",
    "config = pipe.read_conf()\n",
    "arch = config[\"arch\"].lower()\n",
    "config_arch = config.get(arch)\n",
    "\n",
    "# Set-up distributed communication, if using\n",
    "device, is_logger = setup(config)\n",
    "\n",
    "# Make sure we only print information when needed\n",
    "config.verbose = config.verbose and is_logger\n",
    "\n",
    "# Print config to screen\n",
    "if config.verbose and is_logger:\n",
    "    pipe.log()\n",
    "    sys.stdout.flush()\n",
    "\n",
    "model = get_model(config, mean, std, upsampling_factor)\n",
    "model = model.to(device)\n",
    "\n",
    "checkpoint_path = os.path.join(project_dir,'src/neuraloperators',config_arch[\"checkpoint_path\"])\n",
    "if config.checkpoint.save_checkpoint is True:\n",
    "    model.load_state_dict(torch.load(os.path.join(checkpoint_path, 'best_model.pt')))\n",
    "\n",
    "out_channels = config_arch[\"out_channels\"]\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57dd27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "months  = [\n",
    "    str(i).rjust(2,'0') for i in range(1,13,1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a2261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3, 41, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([744, 3, 41, 44])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_vars = ['t2m','u10','v10','tcw']\n",
    "\n",
    "path = './datasets/era5_california/2022/01/data_stream-oper_stepType-instant.nc'\n",
    "\n",
    "file = h5py.File(path)\n",
    "\n",
    "arr = np.stack(file[key] for key in climate_vars)\n",
    "\n",
    "arr = np.transpose(arr, (1,0,2,3))\n",
    "\n",
    "spd = np.sqrt(arr[:,1,:,:]**2 + arr[:,2,:,:]**2)\n",
    "\n",
    "arr = np.stack([arr[:,0,:,:],spd,arr[:,3,:,:]],axis=1)\n",
    "\n",
    "hrs = 24\n",
    "date_aggregate = rearrange(arr,'(f t) c h w -> f t c h w',t=hrs)\n",
    "date_aggregate =np.mean(date_aggregate,axis=1)\n",
    "print(date_aggregate.shape)\n",
    "\n",
    "tensor = torch.from_numpy(arr)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d61bd365",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for month in months:\n",
    "    path = f'./datasets/era5_california/2022/{month}/data_stream-oper_stepType-instant.nc'\n",
    "\n",
    "    file = h5py.File(path)\n",
    "\n",
    "    arr = np.stack(file[key] for key in climate_vars)\n",
    "\n",
    "    arr = np.transpose(arr, (1,0,2,3))\n",
    "\n",
    "    spd = np.sqrt(arr[:,1,:,:]**2 + arr[:,2,:,:]**2)\n",
    "\n",
    "    arr = np.stack([spd,arr[:,0,:,:],arr[:,3,:,:]],axis=1)\n",
    "\n",
    "    hrs = 24\n",
    "    date_aggregate = rearrange(arr,'(f t) c h w -> f t c h w',t=hrs)\n",
    "    date_aggregate =np.mean(date_aggregate,axis=1)\n",
    "\n",
    "\n",
    "    tensor = torch.from_numpy(date_aggregate)\n",
    "    data.append(tensor)\n",
    "\n",
    "data = torch.cat(data,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7ccb731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([365, 3, 41, 44])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1acd1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_batches = len(data) // batch_size\n",
    "\n",
    "downscaled_year = []\n",
    "\n",
    "for i in range(num_batches):\n",
    "    X = data[(i*batch_size):((i+1)*batch_size)].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X_hr = model(X)\n",
    "\n",
    "    sample = X_hr.cpu().detach().numpy()\n",
    "    downscaled_year.append(sample)\n",
    "\n",
    "output = np.concatenate(downscaled_year,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b77d0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape\n",
    "\n",
    "np.save('california_2022_fno_16times_downscale.npy',output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
