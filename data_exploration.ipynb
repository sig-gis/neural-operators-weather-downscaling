{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbaf001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.era5_dataset import ERA5Dataset,means,stds\n",
    "\n",
    "# ee.Authenticate()\n",
    "# ee.Initialize(project='eofm-benchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dfe24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_lat_min = 32.3\n",
    "california_lat_max = 42.2\n",
    "\n",
    "california_lon_min = -124.7\n",
    "california_lon_max = -113.9\n",
    "\n",
    "path = 'datasets/data_era5_2016_02_data_stream-oper_stepType-instant.nc'\n",
    "\n",
    "climate_vars = ['t2m','u10','v10']\n",
    "years = ['2020']\n",
    "\n",
    "months  = [\n",
    "    str(i).rjust(2,'0') for i in range(1,13,1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68614527",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.zeros(len(climate_vars))\n",
    "stds = np.zeros(len(climate_vars))\n",
    "\n",
    "s = np.zeros(len(climate_vars))\n",
    "sum_of_squares = np.zeros(len(climate_vars))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for month in months:\n",
    "    path = f'datasets/{years[0]}/{month}/data_stream-oper_stepType-instant.nc'\n",
    "\n",
    "    with h5py.File(path) as f:\n",
    "        count += len(f['expver']) * len(f['latitude']) * len(f['longitude'])\n",
    "        for i,var in enumerate(climate_vars):\n",
    "            s[i] += np.sum(f[var])\n",
    "            sum_of_squares[i] += np.sum(np.square(f[var]))\n",
    "\n",
    "means = s / count\n",
    "stds = np.sqrt((sum_of_squares / count) - np.square(s / count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d453817",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{means}')\n",
    "print(f'{stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e59138ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['expver', 'latitude', 'longitude', 'number', 'sp', 't2m', 'tcw', 'u10', 'v10', 'valid_time']>\n",
      "(744,)\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "path = f'datasets/era5_new/{years[0]}/{months[0]}/data_stream-oper_stepType-instant.nc'\n",
    "\n",
    "with h5py.File(path,'r') as f:\n",
    "    # f.create_group('01')\n",
    "    print(f.keys())\n",
    "    print(f['expver'].shape)\n",
    "    print(f['expver'].shape[0] // 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = ['2016','2017','2018','2019','2020','2021','2022']\n",
    "# months  = [\n",
    "#     str(i).rjust(2,'0') for i in range(1,13,1)\n",
    "# ]\n",
    "\n",
    "years = ['2020','2021']\n",
    "months  = [\n",
    "    str(i).rjust(2,'0') for i in range(1,13,1)\n",
    "]\n",
    "\n",
    "\n",
    "weather_vars = ['sp', 't2m', 'tcw', 'u10', 'v10']\n",
    "\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        orig_path = f'datasets/era5_new/{year}/{month}/data_stream-oper_stepType-instant.nc'\n",
    "        path = f'datasets/era5_new/{year}/{month}/hourly_data.h5'\n",
    "\n",
    "        file = h5py.File(orig_path,mode='r')\n",
    "        hrs = file['expver']\n",
    "        lat = file['latitude']\n",
    "        lon = file['longitude']\n",
    "\n",
    "        new_file = h5py.File(path,mode='w')\n",
    "\n",
    "        new_file.create_dataset('hrs',data=hrs)\n",
    "        new_file.create_dataset('latitude',data=lat)\n",
    "        new_file.create_dataset('longitude',data=lon)\n",
    "        new_file.create_group('hourly_data')\n",
    "\n",
    "\n",
    "        for i in range(hrs.shape[0]):\n",
    "            new_file.create_group(f'hourly_data/{i}')\n",
    "        for clim_var in weather_vars:\n",
    "            arr = file[clim_var]\n",
    "            for j in range(hrs.shape[0]):\n",
    "                data_point = arr[j,:,:]\n",
    "                new_file.create_dataset(f'hourly_data/{j}/{clim_var}',data=data_point)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef397f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['hourly_data', 'hrs', 'latitude', 'longitude']>\n",
      "(721, 1440)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./datasets/era5_new/2022/01/hourly_data.h5') as f:\n",
    "    print(f.keys())\n",
    "\n",
    "    print(f['hourly_data']['234']['t2m'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e378e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from src.era5_dataset import ERA5Dataset,means,stds\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from timeit import timeit\n",
    "\n",
    "args = {\n",
    "    'data_path':'/home/rpdemilt/climate_downscaling/neural-operators-weather-downscaling/datasets/era5_new/',\n",
    "}\n",
    "\n",
    "climate_vars = [\n",
    "    't2m',\n",
    "    'u10',\n",
    "    'v10'\n",
    "]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[means[clim_var] for clim_var in climate_vars],\n",
    "            std=[stds[clim_var] for clim_var in climate_vars]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "dataset = ERA5Dataset(\n",
    "            location=args['data_path'],\n",
    "            train=False,\n",
    "            transform=transform,\n",
    "            climate_vars=climate_vars\n",
    "        )\n",
    "\n",
    "n = 2000\n",
    "\n",
    "subset = Subset(\n",
    "    dataset=dataset,\n",
    "    indices = np.arange(len(dataset))[:n]\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=subset,\n",
    "    batch_size=32,\n",
    "    num_workers=8\n",
    ")\n",
    "\n",
    "def time_access(dataset):\n",
    "    for i, batch in enumerate(dataset):\n",
    "        X,y = batch\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "downscaling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
